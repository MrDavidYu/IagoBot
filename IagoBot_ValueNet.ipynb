{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom theano import function, config, shared, sandbox\\nimport theano.tensor as T\\nimport numpy\\nimport time\\n\\nvlen = 10 * 30 * 768  # 10 x #cores x # threads per core\\niters = 1000\\n\\nrng = numpy.random.RandomState(22)\\nx = shared(numpy.asarray(rng.rand(vlen), config.floatX))\\nf = function([], T.exp(x))\\nprint(f.maker.fgraph.toposort())\\nt0 = time.time()\\nfor i in range(iters):\\n    r = f()\\nt1 = time.time()\\nprint(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\\nprint(\"Result is %s\" % (r,))\\nif numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\\n    print(\\'Used the cpu\\')\\nelse:\\n    print(\\'Used the gpu\\')\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEBUG: Test whether CPU/GPU is being used\n",
    "'''\n",
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    "\n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], T.exp(x))\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in range(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (302, 3, 10, 10)\n",
      "X_train.shape (241, 3, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# In 'th' mode, the channels dimension (the depth) is at index 1\n",
    "K.set_image_dim_ordering('th') \n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "X = None\n",
    "y = None\n",
    "\n",
    "try:  # X_train\n",
    "    with open(\"value_net_x_input.pickle\",\"rb\") as pickle_in:\n",
    "        X = np.array(pk.load(pickle_in))\n",
    "except IOError:\n",
    "    print(\"IOError\", file=sys.stderr)\n",
    "except EOFError:\n",
    "    print(\"EOFError\", file=sys.stderr)\n",
    "    \n",
    "try:  # y_train\n",
    "    with open(\"value_net_y_input.pickle\",\"rb\") as pickle_in:\n",
    "        y = np.array(pk.load(pickle_in))\n",
    "except IOError:\n",
    "    print(\"IOError\", file=sys.stderr)\n",
    "except EOFError:\n",
    "    print(\"EOFError\", file=sys.stderr)\n",
    "\n",
    "#(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(\"X.shape\", X.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print(\"X_train.shape\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_3 (Convolution2D)  (None, 32, 10, 10)    896         convolution2d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 32, 10, 10)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 32, 10, 10)    9248        dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 32, 5, 5)      0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 32, 5, 5)      0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 800)           0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            8010        flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             11          dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 18165\n",
      "____________________________________________________________________________________________________\n",
      "Train on 241 samples, validate on 61 samples\n",
      "Epoch 1/20\n",
      "241/241 [==============================] - 0s - loss: 0.3054 - val_loss: 0.2021\n",
      "Epoch 2/20\n",
      "241/241 [==============================] - 0s - loss: 0.2120 - val_loss: 0.1865\n",
      "Epoch 3/20\n",
      "241/241 [==============================] - 0s - loss: 0.1889 - val_loss: 0.1833\n",
      "Epoch 4/20\n",
      "241/241 [==============================] - 0s - loss: 0.1935 - val_loss: 0.1738\n",
      "Epoch 5/20\n",
      "241/241 [==============================] - 0s - loss: 0.1812 - val_loss: 0.1666\n",
      "Epoch 6/20\n",
      "241/241 [==============================] - 0s - loss: 0.1759 - val_loss: 0.1606\n",
      "Epoch 7/20\n",
      "241/241 [==============================] - 0s - loss: 0.1665 - val_loss: 0.1534\n",
      "Epoch 8/20\n",
      "241/241 [==============================] - 0s - loss: 0.1617 - val_loss: 0.1476\n",
      "Epoch 9/20\n",
      "241/241 [==============================] - 0s - loss: 0.1485 - val_loss: 0.1421\n",
      "Epoch 10/20\n",
      "241/241 [==============================] - 0s - loss: 0.1431 - val_loss: 0.1361\n",
      "Epoch 11/20\n",
      "241/241 [==============================] - 0s - loss: 0.1323 - val_loss: 0.1286\n",
      "Epoch 12/20\n",
      "241/241 [==============================] - 0s - loss: 0.1218 - val_loss: 0.1268\n",
      "Epoch 13/20\n",
      "241/241 [==============================] - 0s - loss: 0.1160 - val_loss: 0.1240\n",
      "Epoch 14/20\n",
      "241/241 [==============================] - 0s - loss: 0.1146 - val_loss: 0.1237\n",
      "Epoch 15/20\n",
      "241/241 [==============================] - 0s - loss: 0.1106 - val_loss: 0.1195\n",
      "Epoch 16/20\n",
      "241/241 [==============================] - 0s - loss: 0.1009 - val_loss: 0.1217\n",
      "Epoch 17/20\n",
      "241/241 [==============================] - 0s - loss: 0.0978 - val_loss: 0.1183\n",
      "Epoch 18/20\n",
      "241/241 [==============================] - 0s - loss: 0.0919 - val_loss: 0.1169\n",
      "Epoch 19/20\n",
      "241/241 [==============================] - 0s - loss: 0.0906 - val_loss: 0.1135\n",
      "Epoch 20/20\n",
      "241/241 [==============================] - 0s - loss: 0.0922 - val_loss: 0.1162\n",
      "32/61 [==============>...............] - ETA: 0sFinal MSE score 0.116214012758\n"
     ]
    }
   ],
   "source": [
    "# reshape to be [samples][pixels/depth/channels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 3, 10, 10).astype('float32')\n",
    "# X = X.reshape(X.shape[0], 3, 10, 10).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 3, 10, 10).astype('float32')\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "# X_train = X_train / 255.0\n",
    "# X_test = X_test / 255.0\n",
    "\n",
    "# one hot encode outputs\n",
    "# y_train = np_utils.to_categorical(y_train)\n",
    "# y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "'''\n",
    "We can create Keras models and evaluate them with scikit-learn by using handy wrapper objects \n",
    "provided by the Keras library. This is desirable, because scikit-learn excels at evaluating models \n",
    "and will allow us to use powerful data preparation and model evaluation schemes with very few lines of code.\n",
    "'''\n",
    "\n",
    "# The Keras wrappers require a function as an argument. \n",
    "# This function that we must define is responsible for creating the neural network model to be evaluated.\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='same', input_shape=(3, 10, 10), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Convolution2D(32, 3, 3, activation='relu', border_mode='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, input_dim=100, init='normal', activation='relu'))\n",
    "    model.add(Dense(1, init='normal'))\n",
    "    \n",
    "    # Compile model\n",
    "    epochs = 20\n",
    "    lrate = 0.01\n",
    "    decay = lrate/epochs\n",
    "    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "# estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "model.summary()\n",
    "# Fit the model\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), shuffle=True, nb_epoch=20, batch_size=32, verbose=1)\n",
    "# Final evaluation of the model\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Final MSE score\", score)\n",
    "# score = mean_squared_error(y_test, model.predict(X_test))\n",
    "\n",
    "# kfold = KFold(X_train.shape[0], n_folds=10, random_state=seed)\n",
    "# score = cross_val_score(estimator, X_train, y_train, cv=kfold)\n",
    "# print(\"Results: %.2f (%.2f) MSE\" % (score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "32/61 [==============>...............] - ETA: 0s"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-61044d1c0e9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'actual labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predicted labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m61\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "# DEBUG: For visualizing the difference between y_test and model.predict(X_test)\n",
    "\n",
    "x_axis = np.arange(61)\n",
    "s1 = y_test\n",
    "s2 = model.predict(X_test, verbose=1)\n",
    "\n",
    "fig = plt.figure(figsize=(11, 6))\n",
    "plt.plot(x_axis, s1)\n",
    "plt.plot(x_axis, s2)\n",
    "plt.legend(['actual labels', 'predicted labels'], loc='upper left')\n",
    "ax = fig.gca()\n",
    "ax.set_xticks(numpy.arange(0,61, 1))\n",
    "ax.set_yticks(numpy.arange(0,1.,0.1))\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(\"Actual labels: \", s1)\n",
    "print(\"Predicted labels: \", s2)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
